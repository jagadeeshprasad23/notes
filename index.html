<!DOCTYPE html>
<html lang="en">
  <head>
    <title>Bootstrap 5 Example</title>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <link
      href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.1/dist/css/bootstrap.min.css"
      rel="stylesheet"
    />
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.1/dist/js/bootstrap.bundle.min.js"></script>
  </head>
  <body>
    <div class="container-fluid p-5 bg-primary text-white text-center">
      <h1>Machine Learning Notes</h1>
      <p>
        This notes is prepared from Book "Hands-on Machine Learning with
        Scikit-Learn, Keras & TensorFlow"
      </p>
    </div>
    <div class="container mt-5">
      <h4>Background</h4>
      <p>
        In 2006, Geoffrey Hinton et al. published a paper showing how to train a
        deep neural network capable of recognizing handwritten digits with
        state-of-the-art precision (>98%). They branded this technique "deep
        learning". A deep neural network is a (very) simplified model of our
        cerebral cortex, composed of a stack of layers of artificial neurons
      </p>
      <h5>Machine learning is great for:</h5>
      <li>
        Problems for which existing solutions require a lot of fine-tuning or
        long lists of rules (a machine learning model can often simplify code
        and perform better than the traditional approach)
      </li>
      <li>
        Complex problems for which using a traditional approach yields no good
        solution (the best machine learning techniques can perhaps find a
        solution)
      </li>
      <li>
        Fluctuating environments (a machine learning system can easily be
        retrained on new data, always keeping it up to date)
      </li>
      <li>Getting insights about complex problems and large amounts of data</li>
      <h4>Types of Machine Learning Systems</h4>

      There are so many different types of machine learning systems that it is
      useful to classify them in broad categories, based on the following
      criteria:
      <li>
        How they are supervised during training (supervised, unsupervised,
        semi-supervised, self-supervised, and others)
      </li>

      <li>
        Whether or not they can learn incrementally on the fly (online versus
        batch learning)
      </li>

      <li>
        Whether they work by simply comparing new data points to known data
        points, or instead by detecting patterns in the training data and
        building a predictive model, much like scientists do (instance-based
        versus model-based learning)
      </li>

      <h4>Training Supervision</h4>

      ML systems can be classified according to the amount and type of
      supervision they get during training. There are many categories, but we'll
      discuss the main ones:
      <b
        >supervised learning, unsupervised learning, self-supervised learning,
        semi-supervised learning, and reinforcement learning.</b
      >

      <h5>Supervised learning</h5>

      <li>
        In supervised learning, the training set you feed to the algorithm
        includes the desired solutions, called labels.
      </li>

      <li>A typical supervised learning task is classification.</li>
      <li>
        Another typical task is to predict a target numeric value, such as the
        price of a car, given a set of features (mileage, age, brand, etc.).
        This sort of task is called regression.
      </li>
      <li>
        Note that some regression models can be used for classification as well,
        and vice versa. For example, logistic regression is commonly used for
        classification.
      </li>

      <h5>Unsupervised learning</h5>

      <li>
        In unsupervised learning, as you might guess, the training data is
        unlabeled. The system tries to learn without a teacher.
      </li>

      <li>
        Visualization algorithms are also good examples of unsupervised
        learning: A related task is dimensionality reduction, in which the goal
        is to simplify the data without losing too much information.
      </li>

      <li>
        Yet another important unsupervised task is anomaly detection—for
        example, detecting unusual credit card transactions to prevent fraud,
        catching manufacturing defects, or automatically removing outliers from
        a dataset before feeding it to another learning algorithm.
      </li>

      <li>
        A very similar task is novelty detection: it aims to detect new
        instances that look different from all instances in the training set.
      </li>

      <li>
        another common unsupervised task is association rule learning: in which
        the goal is to dig into large amounts of data and discover interesting
        relations between attributes.
      </li>

      <h5>Semi-supervised learning</h5>
      <li>
        Since labeling data is usually time-consuming and costly, you will often
        have plenty of unlabeled instances, and few labeled instances. Some
        algorithms can deal with data that's partially labeled. This is called
        semi-supervised learning.
      </li>

      <li>It will cluster then we need to label it.</li>

      <li>
        Most semi-supervised learning algorithms are combinations of
        unsupervised and supervised algorithms. For example, a clustering
        algorithm may be used to group similar instances together, and then
        every unlabeled instance can be labeled with the most common label in
        its cluster. Once the whole dataset is labeled, it is possible to use
        any supervised learning algorithm.
      </li>

      <h5>Self-supervised learning</h5>
      <li>
        Another approach to machine learning involves actually generating a
        fully labeled dataset from a fully unlabeled one. Again, once the whole
        dataset is labeled, any supervised learning algorithm can be used. This
        approach is called self-supervised learning.
      </li>

      <li>
        The resulting model may be quite useful in itself—for example, to repair
        damaged images or to erase unwanted objects from pictures. But more
        often than not, a model trained using self-supervised learning is not
        the final goal. You'll usually want to tweak and fine-tune the model for
        a slightly different task—one that you actually care about.
      </li>

      <h5>Reinforcement learning</h5>
      <p>
        Reinforcement learning is a very different beast. The learning system,
        called an agent in this context, can observe the environment, select and
        perform actions, and get rewards in return (or penalties in the form of
        negative rewards, as shown in Figure 1-13). It must then learn by itself
        what is the best strategy, called a policy, to get the most reward over
        time. A policy defines what action the agent should choose when it is in
        a given situation.
      </p>

      <h4>Batch Versus Online Learning</h4>
      Another criterion used to classify machine learning systems is whether or
      not the system can learn incrementally from a stream of incoming data.

      <h5>Batch learning</h5>
      In batch learning, the system is incapable of learning incrementally: it
      must be trained using all the available data. This will generally take a
      lot of time and computing resources, so it is typically done offline.
      First the system is trained, and then it is launched into production and
      runs without learning anymore; it just applies what it has learned. This
      is called offline learning.

      <h5>Online learning</h5>
      In online learning, you train the system incrementally by feeding it data
      instances sequentially, either individually or in small groups called
      mini-batches. Each learning step is fast and cheap, so the system can
      learn about new data on the fly, as it arrives.

      <h4>Instance-Based Versus Model-Based Learning</h4>
      One more way to categorize machine learning systems is by how they
      generalize. Most machine learning tasks are about making predictions. This
      means that given a number of training examples, the system needs to be
      able to make good predictions for (generalize to) examples it has never
      seen before. Having a good performance measure on the training data is
      good, but insufficient; the true goal is to perform well on new instances.
      There are two main approaches to generalization: instance-based learning
      and model-based learning.

      <h5>Instance-based learning</h5>

      Possibly the most trivial form of learning is simply to learn by heart. If
      you were to create a spam filter this way, it would just flag all emails
      that are identical to emails that have already been flagged by users—not
      the worst solution, but certainly not the best.

      <h4>Model-based learning and a typical machine learning workflow</h4>

      Another way to generalize from a set of examples is to build a model of
      these examples and then use that model to make predictions. This is called
      model-based learning.

      <li>
        the model to make predictions on new cases, this is called inference
      </li>

      <h4>Main Challenges of Machine Learning</h4>

      <p>
        In short, since your main task is to select a model and train it on some
        data, the two things that can go wrong are “bad model” and “bad data”.
        Let's start with examples of bad data.
      </p>
      <li>
        <b>Insufficient Quantity of Training Data:</b> Machine learning is not
        quite there yet; it takes a lot of data for most machine learning
        algorithms to work properly. Even for very simple problems you typically
        need thousands of examples, and for complex problems such as image or
        speech recognition you may need millions of examples (unless you can
        reuse parts of an existing model).
      </li>
      <li>
        <b>Nonrepresentative Training Data:</b> In order to generalize well, it
        is crucial that your training data be representative of the new cases
        you want to generalize to. This is true whether you use instance-based
        learning or model-based learning.
      </li>
      <li><b>Poor-Quality Data:</b>
        Obviously, if your training data is full of errors, outliers, and noise (e.g.,
        due to poor-quality measurements), it will make it harder for the system to
        detect the underlying patterns, so your system is less likely to perform well.</li>
    </div>
  </body>
</html>
